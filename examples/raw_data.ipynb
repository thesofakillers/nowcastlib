{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "selected-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-leone",
   "metadata": {},
   "source": [
    "# Handling Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-mouse",
   "metadata": {},
   "source": [
    "This notebook will showcase how one may use the Nowcast Library to process raw time series data, particularly with regards to synchronizing data sets coming from different data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-bennett",
   "metadata": {},
   "source": [
    "## Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "funny-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nowcastlib as ncl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "royal-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "addressed-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-details",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-dragon",
   "metadata": {},
   "source": [
    "To make this notebook independent of external data, let's generate our own. We will generate data from 3 different data sources, and then work with that. The data will have different sample rates, perhaps even be irregular, and will be missing data at different time periods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-sunday",
   "metadata": {},
   "source": [
    "First, let's define a function for generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "banner-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(\n",
    "    sr_secs,\n",
    "    start_date,\n",
    "    end_date,\n",
    "    n_cols=1,\n",
    "    sr_stdev=0,\n",
    "    gap_period=0,\n",
    "    gap_size=0,\n",
    "    gap_size_stdev=0,\n",
    "    col_names=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates random time series data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sr_secs : int\n",
    "        The number of seconds between each data point\n",
    "    start_date : string or datetime.datetime or numpy.datetime64\n",
    "        When the generated time series should start\n",
    "    end_date : string or datetime.datetime or numpy.datetime64\n",
    "        When the generated time series should end\n",
    "    n_cols : int, default 1\n",
    "        The number of columns the resulting dataframe should have\n",
    "    sr_stdev : number, default 0\n",
    "        The standard deviation in seconds the sample rate should have,\n",
    "        if an irregular sample rate is desired\n",
    "    gap_period: int, default 0\n",
    "        How many seconds of data between gaps, 0 means we never want gaps\n",
    "    gap_size : int, default 0\n",
    "        How long a gap should be in seconds\n",
    "    gap_size_stdev: number, default 0\n",
    "        The standard deviation in gap size, if the gap size should be irregular\n",
    "    col_names: list of string, default None\n",
    "        List of column names the resulting dataframe should have\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.core.frame.DataFrame\n",
    "        Time-indexed pandas dataframe containing the generated data\n",
    "    \"\"\"\n",
    "    regular_tsteps = np.arange(\n",
    "        start_date, end_date, step=np.timedelta64(sr_secs, \"s\"), dtype=\"datetime64[ms]\"\n",
    "    )\n",
    "    n_frames = len(regular_tsteps)\n",
    "\n",
    "    gap_mask = np.ones(n_frames)\n",
    "    if gap_period > 0:\n",
    "        assert gap_size > 0, \"Can't have 0-length gaps\"\n",
    "        # need to convert from seconds to frames\n",
    "        gap_size = int(gap_size / sr_secs)\n",
    "        gap_size_stdev = gap_size_stdev / sr_secs\n",
    "        gap_period = int(gap_period / sr_secs)\n",
    "\n",
    "        gappy_section_length = n_frames - 2 * gap_period\n",
    "\n",
    "        n_gaps = int(gappy_section_length / gap_size)\n",
    "\n",
    "        deviations = np.random.normal(gap_size, gap_size_stdev, n_gaps) - gap_size\n",
    "        for i in range(n_gaps):\n",
    "            curr_index = i * (gap_period + gap_size)\n",
    "            if (curr_index + gap_size + deviations[i]) < gappy_section_length:\n",
    "                gap_mask[gap_period:-gap_period][\n",
    "                    curr_index : curr_index + int(gap_size + deviations[i])\n",
    "                ] = 0\n",
    "    gap_mask = gap_mask.astype(bool)\n",
    "\n",
    "    tsteps = regular_tsteps\n",
    "    if sr_stdev != 0:\n",
    "        deviations = (\n",
    "            np.random.normal(sr_secs, sr_stdev, n_frames - 2) - sr_secs\n",
    "        ) * 1000\n",
    "        tsteps[1:-1] += deviations.astype(int)\n",
    "    gen_data = pd.DataFrame(np.random.randn(n_frames, n_cols), index=tsteps, columns=col_names)\n",
    "    return gen_data[gap_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "green-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = generate_data(\n",
    "    120,\n",
    "    \"2020-01-01\",\n",
    "    \"2020-01-31\",\n",
    "    n_cols=3,\n",
    "    sr_stdev=30,\n",
    "    gap_period=7 * 12 * 3600,\n",
    "    gap_size=12 * 3600,\n",
    "    gap_size_stdev=3600,\n",
    "    col_names=[\"A\", \"B\", \"C\"]\n",
    ")\n",
    "df2 = generate_data(\n",
    "    110,\n",
    "    \"2020-01-04\",\n",
    "    \"2020-02-09\",\n",
    "    n_cols=4,\n",
    "    sr_stdev=5,\n",
    "    gap_period=12 * 3600,\n",
    "    gap_size=6 * 3600,\n",
    "    gap_size_stdev=1800,\n",
    "    col_names=[\"D\", \"E\", \"F\", \"G\"]\n",
    ")\n",
    "df3 = generate_data(\n",
    "    300,\n",
    "    \"2019-12-25\",\n",
    "    \"2020-01-28\",\n",
    "    n_cols=2,\n",
    "    sr_stdev=60,\n",
    "    gap_period=3 * 3600,\n",
    "    gap_size=3600,\n",
    "    gap_size_stdev=900,\n",
    "    col_names=[\"H\", \"I\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hired-universe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:00:00.000</th>\n",
       "      <td>1.667581</td>\n",
       "      <td>-0.634192</td>\n",
       "      <td>0.743483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:01:59.943</th>\n",
       "      <td>0.917675</td>\n",
       "      <td>0.472471</td>\n",
       "      <td>0.042405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:03:55.704</th>\n",
       "      <td>-0.052225</td>\n",
       "      <td>-0.783350</td>\n",
       "      <td>-0.386847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:06:51.784</th>\n",
       "      <td>0.384053</td>\n",
       "      <td>-0.813646</td>\n",
       "      <td>0.563509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:07:47.981</th>\n",
       "      <td>0.441319</td>\n",
       "      <td>1.207329</td>\n",
       "      <td>-0.034453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                A         B         C\n",
       "2020-01-01 00:00:00.000  1.667581 -0.634192  0.743483\n",
       "2020-01-01 00:01:59.943  0.917675  0.472471  0.042405\n",
       "2020-01-01 00:03:55.704 -0.052225 -0.783350 -0.386847\n",
       "2020-01-01 00:06:51.784  0.384053 -0.813646  0.563509\n",
       "2020-01-01 00:07:47.981  0.441319  1.207329 -0.034453"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'df2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-04 00:00:00.000</th>\n",
       "      <td>-1.298176</td>\n",
       "      <td>0.990171</td>\n",
       "      <td>0.370119</td>\n",
       "      <td>-0.212299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 00:01:53.277</th>\n",
       "      <td>-1.474500</td>\n",
       "      <td>0.776955</td>\n",
       "      <td>0.262370</td>\n",
       "      <td>-0.446278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 00:03:42.522</th>\n",
       "      <td>0.630933</td>\n",
       "      <td>1.075481</td>\n",
       "      <td>-1.654442</td>\n",
       "      <td>-0.149427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 00:05:36.754</th>\n",
       "      <td>-1.421914</td>\n",
       "      <td>-0.219813</td>\n",
       "      <td>-1.653584</td>\n",
       "      <td>0.469912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 00:07:22.248</th>\n",
       "      <td>-0.957144</td>\n",
       "      <td>0.984015</td>\n",
       "      <td>-0.180942</td>\n",
       "      <td>-0.656929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                D         E         F         G\n",
       "2020-01-04 00:00:00.000 -1.298176  0.990171  0.370119 -0.212299\n",
       "2020-01-04 00:01:53.277 -1.474500  0.776955  0.262370 -0.446278\n",
       "2020-01-04 00:03:42.522  0.630933  1.075481 -1.654442 -0.149427\n",
       "2020-01-04 00:05:36.754 -1.421914 -0.219813 -1.653584  0.469912\n",
       "2020-01-04 00:07:22.248 -0.957144  0.984015 -0.180942 -0.656929"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'df3'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-25 00:00:00.000</th>\n",
       "      <td>-0.602310</td>\n",
       "      <td>0.869755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 00:06:12.370</th>\n",
       "      <td>0.172451</td>\n",
       "      <td>-0.959006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 00:10:59.675</th>\n",
       "      <td>0.970407</td>\n",
       "      <td>1.016430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 00:15:28.386</th>\n",
       "      <td>-1.343984</td>\n",
       "      <td>0.494236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 00:19:35.339</th>\n",
       "      <td>-0.211174</td>\n",
       "      <td>0.213945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                H         I\n",
       "2019-12-25 00:00:00.000 -0.602310  0.869755\n",
       "2019-12-25 00:06:12.370  0.172451 -0.959006\n",
       "2019-12-25 00:10:59.675  0.970407  1.016430\n",
       "2019-12-25 00:15:28.386 -1.343984  0.494236\n",
       "2019-12-25 00:19:35.339 -0.211174  0.213945"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\"df1\")\n",
    "display(df1.head())\n",
    "display(\"df2\")\n",
    "display(df2.head())\n",
    "display(\"df3\")\n",
    "display(df3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-merchant",
   "metadata": {},
   "source": [
    "Visualizing the data. Only showing one column from each dataframe since we are mostly interested in the gaps and sampling rate which will be the same across columns of the same dataframe. Two of the dataframes have been vertically shifted to avoid confusion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "organic-demand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e436ed5ce3db42809199a5e59677bf55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_palette(\"Set1\")\n",
    "shift_amount = 4\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(\n",
    "    df1.index, df1[\"A\"] + shift_amount, s=1, label=\"df1 + {}\".format(shift_amount)\n",
    ")\n",
    "plt.scatter(df2.index, df2[\"E\"], s=1, label=\"df2\")\n",
    "plt.scatter(\n",
    "    df3.index, df3[\"H\"] - shift_amount, s=1, label=\"df3 - {}\".format(shift_amount)\n",
    ")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-canon",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-vanilla",
   "metadata": {},
   "source": [
    "### Data Synchronization and Sample-rate regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-pension",
   "metadata": {},
   "source": [
    "If we want to feed our datasets as a joint input to a time series model, often this requires for the data to be regular, i.e. with a constant sample rate, i.e. . The datasets will also have to be merged and hence synced (meaning matching sample rates and dates) into a single dataset for whatever model to receive and reason about them as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-shadow",
   "metadata": {},
   "source": [
    "We can achieve these two features in the following manner. \n",
    "\n",
    "First, we pick a target sample rate. All of our dataframes will be resampled to have this sample rate, so it is best to pick a sample rate that approximates the mean sample rate across the datasets. Two of the three dataframes we are dealing with have a sample rate of \\~2 minutes, and the third one has a sample rate of \\~5 minutes (I use \"\\~\" because the sample rate is not constant), so let's pick a target sample rate of 2 minutes. In resampling, we also make sure that the resample origin is floored so that each dataframe is resampled from the same starting point. This means that if there are overlaps, they will be exact.\n",
    "\n",
    "We then concatenate the resampled dataframes across the 2nd axis (axis=1) perform an inner join on the index, such that only indices that are shared across all dataframes are kept. This is basically an \"intersection\" of the indices, if we're thinking in terms of sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "nervous-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "TARGET_SR = \"2min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "interesting-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resampling\n",
    "data_dfs = [df1, df2, df3]\n",
    "for i, df in enumerate(data_dfs):\n",
    "     data_dfs[i] = df.resample(TARGET_SR, origin=df.index[0].floor(TARGET_SR)\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "significant-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating\n",
    "synced_df = pd.concat(data_dfs, axis=1, join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "secret-crime",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-04 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.386338</td>\n",
       "      <td>0.883563</td>\n",
       "      <td>0.316244</td>\n",
       "      <td>-0.329289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 00:02:00</th>\n",
       "      <td>0.185335</td>\n",
       "      <td>1.060339</td>\n",
       "      <td>-0.282299</td>\n",
       "      <td>0.630933</td>\n",
       "      <td>1.075481</td>\n",
       "      <td>-1.654442</td>\n",
       "      <td>-0.149427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 00:04:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.421914</td>\n",
       "      <td>-0.219813</td>\n",
       "      <td>-1.653584</td>\n",
       "      <td>0.469912</td>\n",
       "      <td>-1.648964</td>\n",
       "      <td>0.858653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 00:06:00</th>\n",
       "      <td>-0.228045</td>\n",
       "      <td>-0.708304</td>\n",
       "      <td>-0.864891</td>\n",
       "      <td>-0.957144</td>\n",
       "      <td>0.984015</td>\n",
       "      <td>-0.180942</td>\n",
       "      <td>-0.656929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04 00:08:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.154188</td>\n",
       "      <td>1.646807</td>\n",
       "      <td>0.215591</td>\n",
       "      <td>-1.236376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            A         B         C         D         E  \\\n",
       "2020-01-04 00:00:00       NaN       NaN       NaN -1.386338  0.883563   \n",
       "2020-01-04 00:02:00  0.185335  1.060339 -0.282299  0.630933  1.075481   \n",
       "2020-01-04 00:04:00       NaN       NaN       NaN -1.421914 -0.219813   \n",
       "2020-01-04 00:06:00 -0.228045 -0.708304 -0.864891 -0.957144  0.984015   \n",
       "2020-01-04 00:08:00       NaN       NaN       NaN -1.154188  1.646807   \n",
       "\n",
       "                            F         G         H         I  \n",
       "2020-01-04 00:00:00  0.316244 -0.329289       NaN       NaN  \n",
       "2020-01-04 00:02:00 -1.654442 -0.149427       NaN       NaN  \n",
       "2020-01-04 00:04:00 -1.653584  0.469912 -1.648964  0.858653  \n",
       "2020-01-04 00:06:00 -0.180942 -0.656929       NaN       NaN  \n",
       "2020-01-04 00:08:00  0.215591 -1.236376       NaN       NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result\n",
    "synced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "worst-virus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bdaf2d9e2b14889a65f6a40925cc1e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_palette(\"Set1\")\n",
    "shift_amount = 4\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
    "ax1.scatter(\n",
    "    df1.index, df1[\"A\"] + shift_amount, s=1, label=\"df1 + {}\".format(shift_amount)\n",
    ")\n",
    "ax1.scatter(df2.index, df2[\"E\"], s=1, label=\"df2\")\n",
    "ax1.scatter(\n",
    "    df3.index, df3[\"H\"] - shift_amount, s=1, label=\"df3 - {}\".format(shift_amount)\n",
    ")\n",
    "ax1.set_title(\"Raw Data\")\n",
    "ax1.legend()\n",
    "ax2.plot(\n",
    "    synced_df.index,\n",
    "    synced_df[\"A\"] + shift_amount,\n",
    "    linewidth=1,\n",
    "    label=\"synced_df df1 + {}\".format(shift_amount),\n",
    ")\n",
    "ax2.plot(\n",
    "    synced_df.index,\n",
    "    synced_df[\"E\"],\n",
    "    linewidth=1,\n",
    "    label=\"synced_df df2\",\n",
    ")\n",
    "ax2.plot(\n",
    "    synced_df.index,\n",
    "    synced_df[\"H\"] - shift_amount,\n",
    "    linewidth=1,\n",
    "    label=\"synced_df df3 - {}\".format(shift_amount),\n",
    ")\n",
    "ax2.set_title(\"Syncronzied and Regularised Dataframes\")\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-damage",
   "metadata": {},
   "source": [
    "### Finding overlapping data and Handling Gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-romantic",
   "metadata": {},
   "source": [
    "Now that our datasets are synchronized, we need to find when they overlap, i.e. when all three datasets are not null. This is, again, so that we can obtain chunks that our models can treat and reason about as a whole. This is also because our models are not able to handle NaN values in the input.\n",
    "\n",
    "Normally, we could just find where the gaps are and then perform a set union of the gaps across the datasets. This would give us all the indices where at least one dataset has a gap, which we would then drop. \n",
    "\n",
    "However, resampling gave rise to many small gaps, which may be sufficiently small for us to impute with, for example, linear interpolation.\n",
    "\n",
    "As such, we need to distinguish between small and large gaps. We will keep track of where the large gaps are by producing a boolean mask, impute the entire dataframe, and then drop the indices where the large gaps occurred, using the mask.\n",
    "\n",
    "---\n",
    "\n",
    "**Side note**: we may wish to perform additional computations on the data after interpolation which could result in extra columns (such as, for example, computing trigonometric equivalents of particular columns). Because the gap mask has to have the same shape as the dataframe it is being applied to, we need to specify the number of additional columns we expect to add when computing the large gap mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "theoretical-navigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "# the maximum size of a 'small gap' in seconds. let's say 10 minutes\n",
    "MAX_SPACING_SECS = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "productive-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing large gap mask\n",
    "sample_spacing_secs = synced_df.index.freq.delta.seconds\n",
    "max_spacing_steps = np.floor((MAX_SPACING_SECS / sample_spacing_secs)).astype(int)\n",
    "final_mask = ncl.rawdata.compute_dataframe_mask(\n",
    "    input_df=synced_df,\n",
    "    max_gap=max_spacing_steps,\n",
    "    additional_cols_n=2,\n",
    "    column_names=[df.columns[0] for df in data_dfs],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "noble-execution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d54f4705124468a96139f912549f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizing our mask\n",
    "sns.set_palette(\"Set1\")\n",
    "shift_amount = 4\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
    "ax1.plot(\n",
    "    synced_df.index,\n",
    "    synced_df[\"A\"] + shift_amount,\n",
    "    linewidth=1,\n",
    "    label=\"synced_df df1 + {}\".format(shift_amount),\n",
    ")\n",
    "ax1.plot(\n",
    "    synced_df.index,\n",
    "    synced_df[\"E\"],\n",
    "    linewidth=1,\n",
    "    label=\"synced_df df2\",\n",
    ")\n",
    "ax1.plot(\n",
    "    synced_df.index,\n",
    "    synced_df[\"H\"] - shift_amount,\n",
    "    linewidth=1,\n",
    "    label=\"synced_df df3 - {}\".format(shift_amount),\n",
    ")\n",
    "ax1.set_title(\"Syncronzied and Regularised Dataframes\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.step(synced_df.index, final_mask, label=\"large gap mask\", color='black')\n",
    "ax2.fill_between(synced_df.index, final_mask[:,0], step='pre', color='black')\n",
    "ax2.set_title(\"Large Gap Mask\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-continent",
   "metadata": {},
   "source": [
    "The mask is 0 (or False), where large gaps occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "planned-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolating our data\n",
    "interpolated_df = synced_df.interpolate(\"linear\", limit_direction=\"both\")\n",
    "# adding addtional columns\n",
    "interpolated_df = ncl.rawdata.compute_trig_fields(interpolated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "finished-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping large gaps using mask\n",
    "chunked_df = interpolated_df.where(final_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "permanent-ivory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7d9595a3e5404d85a45f79eb00739a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizing\n",
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "for df, df_string, title, ax in zip(\n",
    "    [synced_df, interpolated_df, chunked_df],\n",
    "    [\"synced_df\", \"interpolated_df\", \"chunked_df\"],\n",
    "    [\n",
    "        \"Syncronzied and Regularised Dataframes\",\n",
    "        \"Interpolated Dataframes\",\n",
    "        \"Chunked Dataframes\",\n",
    "    ],\n",
    "    [ax1, ax2, ax3],\n",
    "):\n",
    "    ax.plot(\n",
    "        df.index,\n",
    "        df[\"A\"] + shift_amount,\n",
    "        linewidth=1,\n",
    "        label=\"{0} df1 + {1}\".format(df_string, shift_amount),\n",
    "    )\n",
    "    ax.plot(\n",
    "        df.index,\n",
    "        df[\"E\"],\n",
    "        linewidth=1,\n",
    "        label=\"{0} df2\".format(df_string, shift_amount),\n",
    "    )\n",
    "    ax.plot(\n",
    "        df.index,\n",
    "        df[\"H\"] - shift_amount,\n",
    "        linewidth=1,\n",
    "        label=\"{0} df3 - {1}\".format(df_string, shift_amount),\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "\n",
    "ax4.step(synced_df.index, final_mask, label=\"large gap mask\", color='black')\n",
    "ax4.fill_between(synced_df.index, final_mask[:,0], step='pre', color='black')\n",
    "ax4.set_title(\"Large Gap Mask\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-canada",
   "metadata": {},
   "source": [
    "### Final Cleanup and Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-drunk",
   "metadata": {},
   "source": [
    "Because of the chunk-like aspect of the resulting dataframe, we will split it into individual chunk dataframes, and save these to an HDF5 filestore. In doing so, we can additionally choose to ignore chunks that are shorter than some minimum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "yellow-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "MIN_CHUNK_DURATION_SEC = 3600\n",
    "OUTPUT_PATH = \"output/processedrawdata.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "alternate-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunking\n",
    "min_chunk_length = int(MIN_CHUNK_DURATION_SEC / sample_spacing_secs)\n",
    "chunks = ncl.rawdata.make_chunks(chunked_df, min_chunk_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hundred-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving to disk\n",
    "hdfs = pd.HDFStore(OUTPUT_PATH)\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk.to_hdf(hdfs, \"chunk_{:d}\".format(i), format=\"table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-valuation",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-summer",
   "metadata": {},
   "source": [
    "We have successfully regularized and synchronized 3 different datasets with different irregular sample rates and missing data using functions from the `rawdata` submodule of Nowcast Library. We were also able to find exactly where these datasets overlapped, taking into account our preferences in acceptable gap chunk sizes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "references.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
