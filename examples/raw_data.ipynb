{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "independent-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-sessions",
   "metadata": {},
   "source": [
    "# Handling Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-destruction",
   "metadata": {},
   "source": [
    "This notebook will showcase how one may use the Nowcast Library to process raw time series data, particularly with regards to synchronizing data sets coming from different data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-delay",
   "metadata": {},
   "source": [
    "## Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "infrared-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "textile-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "powered-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-chambers",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-gilbert",
   "metadata": {},
   "source": [
    "To make this notebook independent of external data, let's generate our own. We will generate data from 3 different data sources, and then work with that. The data will have different sample rates, perhaps even be irregular, and will be missing data at different time periods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-edgar",
   "metadata": {},
   "source": [
    "First, let's define a function for generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "expected-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(\n",
    "    sr_secs,\n",
    "    start_date,\n",
    "    end_date,\n",
    "    n_cols=1,\n",
    "    sr_stdev=0,\n",
    "    gap_period=0,\n",
    "    gap_size=0,\n",
    "    gap_size_stdev=0,\n",
    "    col_names=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates random time series data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sr_secs : int\n",
    "        The number of seconds between each data point\n",
    "    start_date : string or datetime.datetime or numpy.datetime64\n",
    "        When the generated time series should start\n",
    "    end_date : string or datetime.datetime or numpy.datetime64\n",
    "        When the generated time series should end\n",
    "    n_cols : int, default 1\n",
    "        The number of columns the resulting dataframe should have\n",
    "    sr_stdev : number, default 0\n",
    "        The standard deviation in seconds the sample rate should have,\n",
    "        if an irregular sample rate is desired\n",
    "    gap_period: int, default 0\n",
    "        How many seconds of data between gaps, 0 means we never want gaps\n",
    "    gap_size : int, default 0\n",
    "        How long a gap should be in seconds\n",
    "    gap_size_stdev: number, default 0\n",
    "        The standard deviation in gap size, if the gap size should be irregular\n",
    "    col_names: list of string, default None\n",
    "        List of column names the resulting dataframe should have\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.core.frame.DataFrame\n",
    "        Time-indexed pandas dataframe containing the generated data\n",
    "    \"\"\"\n",
    "    regular_tsteps = np.arange(\n",
    "        start_date, end_date, step=np.timedelta64(sr_secs, \"s\"), dtype=\"datetime64[ms]\"\n",
    "    )\n",
    "    n_frames = len(regular_tsteps)\n",
    "\n",
    "    gap_mask = np.ones(n_frames)\n",
    "    if gap_period > 0:\n",
    "        assert gap_size > 0, \"Can't have 0-length gaps\"\n",
    "        # need to convert from seconds to frames\n",
    "        gap_size = int(gap_size / sr_secs)\n",
    "        gap_size_stdev = gap_size_stdev / sr_secs\n",
    "        gap_period = int(gap_period / sr_secs)\n",
    "\n",
    "        gappy_section_length = n_frames - 2 * gap_period\n",
    "\n",
    "        n_gaps = int(gappy_section_length / gap_size)\n",
    "\n",
    "        deviations = np.random.normal(gap_size, gap_size_stdev, n_gaps) - gap_size\n",
    "        for i in range(n_gaps):\n",
    "            curr_index = i * (gap_period + gap_size)\n",
    "            if (curr_index + gap_size + deviations[i]) < gappy_section_length:\n",
    "                gap_mask[gap_period:-gap_period][\n",
    "                    curr_index : curr_index + int(gap_size + deviations[i])\n",
    "                ] = 0\n",
    "    gap_mask = gap_mask.astype(bool)\n",
    "\n",
    "    tsteps = regular_tsteps\n",
    "    if sr_stdev != 0:\n",
    "        deviations = (\n",
    "            np.random.normal(sr_secs, sr_stdev, n_frames - 2) - sr_secs\n",
    "        ) * 1000\n",
    "        tsteps[1:-1] += deviations.astype(int)\n",
    "    gen_data = pd.DataFrame(np.random.randn(n_frames, n_cols), index=tsteps, columns=col_names)\n",
    "    return gen_data[gap_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "backed-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = generate_data(\n",
    "    120,\n",
    "    \"2020-01-01\",\n",
    "    \"2020-01-31\",\n",
    "    n_cols=3,\n",
    "    sr_stdev=30,\n",
    "    gap_period=7 * 12 * 3600,\n",
    "    gap_size=12 * 3600,\n",
    "    gap_size_stdev=3600,\n",
    "    col_names=[\"A\", \"B\", \"C\"]\n",
    ")\n",
    "df2 = generate_data(\n",
    "    110,\n",
    "    \"2020-01-04\",\n",
    "    \"2020-02-09\",\n",
    "    n_cols=4,\n",
    "    sr_stdev=5,\n",
    "    gap_period=12 * 3600,\n",
    "    gap_size=6 * 3600,\n",
    "    gap_size_stdev=1800,\n",
    "    col_names=[\"D\", \"E\", \"F\", \"G\"]\n",
    ")\n",
    "df3 = generate_data(\n",
    "    300,\n",
    "    \"2019-12-25\",\n",
    "    \"2020-01-28\",\n",
    "    n_cols=2,\n",
    "    sr_stdev=60,\n",
    "    gap_period=3 * 3600,\n",
    "    gap_size=3600,\n",
    "    gap_size_stdev=900,\n",
    "    col_names=[\"H\", \"I\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-north",
   "metadata": {},
   "source": [
    "Visualizing the data. Only showing one column from each dataframe since we are mostly interested in the gaps and sampling rate which will be the same across columns of the same dataframe. Two of the dataframes have been vertically shifted to avoid confusion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "usual-auckland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d38040028e4965b7eb4c2f0a1c8d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_palette(\"Set1\")\n",
    "shift_amount = 4\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(\n",
    "    df1.index, df1[\"A\"] + shift_amount, s=1, label=\"df1 + {}\".format(shift_amount)\n",
    ")\n",
    "plt.scatter(df2.index, df2[\"E\"], s=1, label=\"df2\")\n",
    "plt.scatter(\n",
    "    df3.index, df3[\"H\"] - shift_amount, s=1, label=\"df3 - {}\".format(shift_amount)\n",
    ")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-prison",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-expansion",
   "metadata": {},
   "source": [
    "### Data Synchronization and Sample-rate regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-search",
   "metadata": {},
   "source": [
    "If we want to feed our datasets as a joint input to a time series model, often this requires for the data to be regular, i.e. with a constant sample rate, i.e. . The datasets will also have to be merged and hence synced (meaning matching sample rates and dates) into a single dataset for whatever model to receive and reason about them as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-invitation",
   "metadata": {},
   "source": [
    "We can achieve these two features in the following manner. \n",
    "\n",
    "First, we pick a target sample rate. All of our dataframes will be resampled to have this sample rate, so it is best to pick a sample rate that approximates the mean sample rate across the datasets. Two of the three dataframes we are dealing with have a sample rate of \\~2 minutes, and the third one has a sample rate of \\~5 minutes (I use \"\\~\" because the sample rate is not constant), so let's pick a target sample rate of 2 minutes. In resampling, we also make sure that the resample origin is floored so that each dataframe is resampled from the same starting point. This means that if there are overlaps, they will be exact.\n",
    "\n",
    "We then concatenate the resampled dataframes across the 2nd axis (axis=1) perform an inner join on the index, such that only indices that are shared across all dataframes are kept. This is basically an \"intersection\" of the indices, if we're thinking in terms of sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "final-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "TARGET_SR = \"2min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "planned-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resampling\n",
    "dfs = [df1, df2, df3]\n",
    "for i, df in enumerate(dfs):\n",
    "     dfs[i] = df.resample(TARGET_SR, origin=df.index[0].floor(TARGET_SR)\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "brazilian-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating\n",
    "synced_df = pd.concat(dfs, axis=1, join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "sticky-detector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15bcd623b6484dda9f07abc6db776f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_palette(\"Set1\")\n",
    "shift_amount = 4\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
    "ax1.scatter(\n",
    "    df1.index, df1[\"A\"] + shift_amount, s=1, label=\"df1 + {}\".format(shift_amount)\n",
    ")\n",
    "ax1.scatter(df2.index, df2[\"E\"], s=1, label=\"df2\")\n",
    "ax1.scatter(\n",
    "    df3.index, df3[\"H\"] - shift_amount, s=1, label=\"df3 - {}\".format(shift_amount)\n",
    ")\n",
    "ax1.set_title(\"Raw Data\")\n",
    "ax1.legend()\n",
    "ax2.scatter(\n",
    "    synced_df.index,\n",
    "    synced_df[\"A\"] + shift_amount,\n",
    "    s=1,\n",
    "    label=\"synced_df df1 + {}\".format(shift_amount),\n",
    ")\n",
    "ax2.scatter(\n",
    "    synced_df.index,\n",
    "    synced_df[\"E\"],\n",
    "    s=1,\n",
    "    label=\"synced_df df2\",\n",
    ")\n",
    "ax2.scatter(\n",
    "    synced_df.index,\n",
    "    synced_df[\"H\"] - shift_amount,\n",
    "    s=1,\n",
    "    label=\"synced_df df3 - {}\".format(shift_amount),\n",
    ")\n",
    "ax2.set_title(\"Syncronzied and Regularised Dataframes\")\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-spain",
   "metadata": {},
   "source": [
    "### Finding overlapping data and Handling Gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-prince",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "references.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
